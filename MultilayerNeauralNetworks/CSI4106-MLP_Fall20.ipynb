{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6 - Neural Networks (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI4106 Artificial Intelligence  \n",
    "Fall 2020  \n",
    "Prepared by Julian Templeton and Caroline Barrière"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***INTRODUCTION***:  \n",
    "\n",
    "We are going into the medical domain for this notebook. The supervised classification task tackled in this notebook is about diabetes patient readmission to a hospital, provided a certain set of features describing their physical state, the procedure they went through during their stay, the medications they take, etc.\n",
    "\n",
    "Any *readmitted patient* is very costly for a medical system. It shows to some extent, that the patient was discharged before having fully recovered. The dataset we explore splits readmission into 3 values: before 30 days, after 30 days, and none.  Understanding what conditions brings patients back to the hospital within 30 days is very important for a medical system, as these cases should be minimized.\n",
    "\n",
    "This notebook will allow you to pursue your understanding of experimental set-up for supervised machine learning, in particular supervised classification through the use of multi-layer perceptrons.\n",
    "\n",
    "We will make use of three packages: (1) **scikit-learn**, a great machine learning package, which you've experimented with in the last notebook, (2) **pandas**, a must-have for data science, and (3) **matplotlib** which is a great plotting library (pip install matplotlib).  Make sure you have the LATEST version of scikit-learn (at least version >= 0.20), otherwise some functions (the one-hot-encoder) will not work.\n",
    "\n",
    "As this is your 6th notebook this semester, some instructions will be a bit less explicit and may require looking at some online official documentation. If you have any assumptions state them and think about how to handle the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***HOMEWORK***:  \n",
    "Go through the notebook by running each cell, one at a time.  \n",
    "Look for **(TO DO)** for the tasks that you need to perform. Do not edit the code outside of the questions which you are asked to answer unless specifically asked. Once you're done, Sign the notebook (at the end of the notebook), and submit it.  \n",
    "\n",
    "*The notebook will be marked on 30.  \n",
    "Each **(TO DO)** has a number of points associated with it.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Obtaining the dataset**\n",
    "\n",
    "First, read the description of the dataset on Diabetes Readmission (https://www.kaggle.com/brandao/diabetes).\n",
    "\n",
    "Next download the dataset from the UCI archive (click *Data Folder* --> download *dataset_diabetes.zip*):\n",
    "https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008\n",
    "\n",
    "Unzip the file *dataset_diabetes.zip* and there should be a file called *diabetic_data.csv* which we will use for our experiments. The file must be located at *dataset_diabetes/diabetic_data.csv* from the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Exploring the dataset**  \n",
    "We will use the package *pandas* to read the csv file. Pandas will create a data structure called a dataframe, which will contain all the data. Dataframes are a crucial data structure that allows makes it very easy to analyze the data that you are working with, retrieve subsets of the data based on search conditions, and utilize the data in Machine Learning algorithms.\n",
    "\n",
    "If you get some errors when you import the packages, it's because they are not installed... make sure you do *pip install package_name* (or whichever method you have been using to install the packages) at the command prompt to have access to these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages for data analysis and machine learning\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads the csv file into a dataframe and shows the top ten rows from the read data.  \n",
    "Note that ? means that the value is *missing* from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35754</td>\n",
       "      <td>82637451</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55842</td>\n",
       "      <td>84259809</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63768</td>\n",
       "      <td>114882984</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12522</td>\n",
       "      <td>48330783</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15738</td>\n",
       "      <td>63555939</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[90-100)</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender       age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female    [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female   [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female   [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male   [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male   [40-50)      ?   \n",
       "5         35754     82637451        Caucasian    Male   [50-60)      ?   \n",
       "6         55842     84259809        Caucasian    Male   [60-70)      ?   \n",
       "7         63768    114882984        Caucasian    Male   [70-80)      ?   \n",
       "8         12522     48330783        Caucasian  Female   [80-90)      ?   \n",
       "9         15738     63555939        Caucasian  Female  [90-100)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "5                  2                         1                    2   \n",
       "6                  3                         1                    2   \n",
       "7                  1                         1                    7   \n",
       "8                  2                         1                    4   \n",
       "9                  3                         3                    4   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "5                 3  ...          No  Steady                   No   \n",
       "6                 4  ...          No  Steady                   No   \n",
       "7                 5  ...          No      No                   No   \n",
       "8                13  ...          No  Steady                   No   \n",
       "9                12  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "5                   No                        No                       No   \n",
       "6                   No                        No                       No   \n",
       "7                   No                        No                       No   \n",
       "8                   No                        No                       No   \n",
       "9                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "5                      No      No         Yes        >30  \n",
       "6                      No      Ch         Yes         NO  \n",
       "7                      No      No         Yes        >30  \n",
       "8                      No      Ch         Yes         NO  \n",
       "9                      No      Ch         Yes         NO  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "X = pd.read_csv(\"dataset_diabetes/diabetic_data.csv\")\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encounter_id',\n",
       " 'patient_nbr',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'weight',\n",
       " 'admission_type_id',\n",
       " 'discharge_disposition_id',\n",
       " 'admission_source_id',\n",
       " 'time_in_hospital',\n",
       " 'payer_code',\n",
       " 'medical_specialty',\n",
       " 'num_lab_procedures',\n",
       " 'num_procedures',\n",
       " 'num_medications',\n",
       " 'number_outpatient',\n",
       " 'number_emergency',\n",
       " 'number_inpatient',\n",
       " 'diag_1',\n",
       " 'diag_2',\n",
       " 'diag_3',\n",
       " 'number_diagnoses',\n",
       " 'max_glu_serum',\n",
       " 'A1Cresult',\n",
       " 'metformin',\n",
       " 'repaglinide',\n",
       " 'nateglinide',\n",
       " 'chlorpropamide',\n",
       " 'glimepiride',\n",
       " 'acetohexamide',\n",
       " 'glipizide',\n",
       " 'glyburide',\n",
       " 'tolbutamide',\n",
       " 'pioglitazone',\n",
       " 'rosiglitazone',\n",
       " 'acarbose',\n",
       " 'miglitol',\n",
       " 'troglitazone',\n",
       " 'tolazamide',\n",
       " 'examide',\n",
       " 'citoglipton',\n",
       " 'insulin',\n",
       " 'glyburide-metformin',\n",
       " 'glipizide-metformin',\n",
       " 'glimepiride-pioglitazone',\n",
       " 'metformin-rosiglitazone',\n",
       " 'metformin-pioglitazone',\n",
       " 'change',\n",
       " 'diabetesMed',\n",
       " 'readmitted']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all attributes\n",
    "list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 50)\n",
      "Caucasian          76099\n",
      "AfricanAmerican    19210\n",
      "?                   2273\n",
      "Hispanic            2037\n",
      "Other               1506\n",
      "Asian                641\n",
      "Name: race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examples of data exploration\n",
    "print(X.shape)\n",
    "print(X['race'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q1 - 3 marks**  \n",
    "Inspired by the code above, *write code* to answer the following questions (not just manually printing a number without finding that number in the code). Your code must help in finding the answer. Print the question that you are answering along with the answer that the code helped find (can manually write specific code, as long as the code helps to get the answer).\n",
    "\n",
    "1. How many examples are in the dataset?\n",
    "2. How many features are in the dataset?\n",
    "3. How many target classes are in the dataset?\n",
    "4. What are the possible weight ranges (including ?), and the number of examples in each?\n",
    "5. What are the prior probabilities of each class (NO, <30, >30)?\n",
    "6. Are there any patients present in the dataset more than 25 times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101766\n",
      "50\n",
      "NO     54864\n",
      ">30    35545\n",
      "<30    11357\n",
      "Name: readmitted, dtype: int64\n",
      "?            98569\n",
      "[75-100)      1336\n",
      "[50-75)        897\n",
      "[100-125)      625\n",
      "[125-150)      145\n",
      "[25-50)         97\n",
      "[0-25)          48\n",
      "[150-175)       35\n",
      "[175-200)       11\n",
      ">200             3\n",
      "Name: weight, dtype: int64\n",
      "96210942     1\n",
      "89943846     1\n",
      "384306986    1\n",
      "94650156     1\n",
      "83156784     1\n",
      "            ..\n",
      "74454612     1\n",
      "208073976    1\n",
      "166229592    1\n",
      "38340702     1\n",
      "77856768     1\n",
      "Name: encounter_id, Length: 101766, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE -- Write which question it answers\n",
    "# 1. How many examples are in the dataset? \n",
    "print(len(X))\n",
    "#2\n",
    "print(len(X.columns))\n",
    "#3\n",
    "print(X['readmitted'].value_counts())\n",
    "#4\n",
    "print(X['weight'].value_counts())\n",
    "#5\n",
    "print(X['encounter_id'].value_counts())\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Feature Selection**  \n",
    "Now that we have taken a look into our data and played with it, we will decide which features would be suitable to use with our model.\n",
    "\n",
    "Feature selection is just as important as tuning a model (choosing hyperparameters such as the number of layers and their sizes). We need to be sure to choose high quality features that best represent our data in order to maximize the performance of our model. Simply putting every feature or selecting some without analyzing them may provide worse results. Thus, we need to consider which features to use by looking at the data itself to see if it would be a good match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some issues when working with data include:\n",
    "1. Is the data well distributed? That is, does it contain enough variety to provide a good split on the data.\n",
    "2. Are there missing values? The more missing values --> the less well these will work as features for many Machine Learning algorithms. Here, we will not focus on this issue, but it is important to know.\n",
    "3. Does this data represent our dataset well.\n",
    "4. Does the data work well with our selected algorithm (here is does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q2 - 4 marks**   \n",
    "In this notebook we will work with the following features along with a few others:  \n",
    "1. gender \n",
    "2. age \n",
    "3. weight \n",
    "4. num_medications\n",
    "\n",
    "Explore each of the specified features by:   \n",
    "\n",
    "1) Plotting the distribution (histogram using kind=\"hist\" for numerical data or bar plots using kind=\"barh\" for categorical data) and write if the data is well distributed   \n",
    "2) Identifying the number of missing/unknown/invalid values\n",
    "\n",
    "Remember, if you have any assumptions that you need to state, state them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for the feature \"race\"\n",
    "plt.figure() # Creates a new figure\n",
    "X[\"race\"].value_counts().plot(kind=\"barh\", title=\"EXAMPLE - Race Distribution\")\n",
    "plt.show()\n",
    "print(\"(Example.1): Is the above output well distributed? No it is not. This feature is highly imbalanced.\")\n",
    "print(\"(Example.2): There are 2273 missing values labelled as '?'.\")\n",
    "\n",
    "print(\"------------------------------ ^ Example ^ ------------------------------\\n\")\n",
    "\n",
    "# MODIFY AND ANSWER THE BELOW BASED ON THE EXAMPLE ABOVE.\n",
    "# gender\n",
    "print(\"(1.1): Is the feature 'gender' well distributed? ...\")\n",
    "print(\"(1.2): There are ... missing values ...\")\n",
    "# age\n",
    "print(\"(2.1): Is the feature 'age' well distributed? ...\")\n",
    "print(\"(2.2): There are ... missing values ...\")\n",
    "# weight\n",
    "print(\"(3.1): Is the feature 'weight' well distributed? ...\")\n",
    "print(\"(3.2): There are ... missing values ...\")\n",
    "# num_medications\n",
    "print(\"(4.1): Is the feature 'num_medications' well distributed? ...\")\n",
    "print(\"(4.2): There are ... missing values ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Preparing the dataset for experimentation**\n",
    "\n",
    "We will do different steps to prepare the data for experimentations:  (1) extracting the class we wish to predict, (2) splitting the dataset into a training and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can ONLY BE DONE ONCE, as we pop the values into a new variable to be used as predicted class\n",
    "y = X.pop(\"readmitted\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the large dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=5)\n",
    "# Look at the shape of the outputs\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Setting up our one-hot encoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Since the dataset is quite large, try with a subset of features\n",
    "featureSet = ['race','gender','age', 'weight', 'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    " 'num_medications']\n",
    "\n",
    "# Make a copy of the training set containing only the chosen features\n",
    "X_train_sf = X_train[featureSet].copy()\n",
    "X_test_sf = X_test[featureSet].copy()\n",
    "\n",
    "# IF you wanted to try with the full dataset, try to redo the steps with this (optional - takes a lot of time)\n",
    "# X_train_allf = X_train[:].copy()\n",
    "# X_test_allf = X_test[:].copy()\n",
    "\n",
    "# Perform the one-hot encoding using our one-hot encoder on the selected feature set\n",
    "ohe.fit(X_train_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one-hot-encoder renames the features. Let's take a look at the new names.\n",
    "feature_names = ohe.get_feature_names()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now encode the training and test set with the new features\n",
    "X_train_sf_encoded = ohe.transform(X_train_sf)\n",
    "X_test_sf_encoded = ohe.transform(X_test_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q3 - 1 mark**   \n",
    "How many features are there now, after the one-hot-encoder? Why so many? Show the shape of the training set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many features are there now (must get from code)?\n",
    "# \n",
    "# Why so many?\n",
    "#\n",
    "# Show the shape of the training set after the one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Baseline model**  \n",
    "Now that we have setup our encoded features we will start by using a Logistic Regression Classifier to perform supervised learning on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***5.1 Defining the Logistic Regression Classifier***   \n",
    "First we will define our Logistic Regression Classifier with scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Logistic Regression model from scikit and matplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "clf_lr = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\", max_iter=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***5.2 Training the Logistic Regression Classifier***  \n",
    "Now that the model is defined, we need to train our model with the train set to learn how to classify our target class *readmitted*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains a given model and returns a list of scores\n",
    "#   clf:     The untrained model to train\n",
    "#   X_train: The encoded attributes of the training set\n",
    "#   y_train: The target values of the training set\n",
    "def train_model(clf, X_train, y_train, epochs=10):\n",
    "    scores = []\n",
    "    print(\"Starting training...\")\n",
    "    for i in range(1, epochs + 1):\n",
    "        print(\"Epoch:\" + str(i) + \"/\" + str(epochs) + \" -- \" + str(datetime.datetime.now()))\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_train, y_train)\n",
    "        scores.append(score)\n",
    "    print(\"Done training.\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q4 - 1 mark**   \n",
    "Looking at the function train_model, what is the *score* (clf.score())? You may need to look at the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for the LogisticRegression to understand this. Explain below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 - ANSWER HERE   \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train the model (recall that we use the training set)\n",
    "# We run for only one epoch and will only get one score\n",
    "clf_lr_scores = train_model(clf_lr, X_train_sf_encoded, y_train, 1)\n",
    "print(clf_lr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5 - 2 marks**   \n",
    "In the answer field below, describe what the output from the code below means and what the code is doing.  \n",
    "Afterwards, give the accuracy of the printed results (just manually state it, no need to code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the prediction on the first 10 examples\n",
    "y_predicted = clf_lr.predict(X_train_sf_encoded[0:10])\n",
    "print(y_predicted)\n",
    "print(y_train[0:10])\n",
    "clf_lr.predict_proba(X_train_sf_encoded[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO - Answers   \n",
    "\n",
    "1) Describe what y_predicted is:   \n",
    "2) Describe what y_train[0:10] is:   \n",
    "3) Describe clf_lr.predict_proba(X_train_sf_encoded[0:10]):   \n",
    "4) What is the accuracy of the printed results? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3 Testing the Logistic Regression Model**   \n",
    "Now that we have our trained model, let's test it on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q6 - 2 marks**   \n",
    "Evaluate the model on the test set by computing it's *score* (recall how the score is computed when training) and compare that to the training set scores (you have this value from clf_lr_scores). Print which is better and give one reason why these results may have ended up this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test set is encoded in here: X_test_sf_encoded\n",
    "# Need to compute test score, print it, compare to train score, and print which is better and why\n",
    "# ....\n",
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. MLP**   \n",
    "After working with our Baseline model, let's try using a Multi Layer Perceptron Classifier to try to perform supervised learning on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***6.1 Defining the MLPClassifier***   \n",
    "First we will define our MLPClassifier with scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MLP model from scikit and matplot\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(150, 150), random_state=5, max_iter=120, learning_rate_init=0.01, warm_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q7 - 3 marks**   \n",
    "Explain *in your own words* the parameters chosen above. What do they all mean and explain how the chosen values for each parameter will affect the model. For any that are unfamiliar, explore the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) and just provide a short sentence on what the parameter does based on its description and your existing knowledge.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7 - ANSWER HERE   \n",
    "\n",
    "*solver:*  \n",
    "*alpha:*  \n",
    "*hidden_layer_size:*  \n",
    "*random_state:*  \n",
    "*max_iter:*  \n",
    "*learning_rate_init:*  \n",
    "*warm_start:*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***6.2 Training, Testing, and Discussing the MLPClassifier***  \n",
    "Now that the model is defined, we need to train our model with the train set to learn how to classify our target class *readmitted*. This time we will be training the MLP model for several epochs with an updated training algorithm. Finally we will plot our retrieved scores, discuss them, and compare them with with the Baseline Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the train and the test scores\n",
    "def plotScores(scores_train, scores_test):\n",
    "    # Plot the points\n",
    "    plt.plot([i for i in range(len(scores_train))], scores_train)\n",
    "    plt.plot([i for i in range(len(scores_test))], scores_test)\n",
    "    # Setup the legend\n",
    "    plt.legend([\"Train scores\", \"Test Scores\"])\n",
    "    # Labels for the x and y axis\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q8 - 6 marks**   \n",
    "\n",
    "***For all parts of this question, ensure that you have the full, correct output in your submission (do not clear the output here).***\n",
    "\n",
    "1. You must define the function train_and_evaluate() below. This function must take as input a classifier, the training set, the testing set, and the number of epochs. Inspired from the provided function train_model(), train the model as usual (use 10 epochs as the default), but now track the scores from both the train and the test sets at each epoch. Return both of these results.  \n",
    "2. Once defined, train clf_mlp with train_and_evaluate() for ten epochs.\n",
    "3. Take the MLPClassifier results and plot them with the plotting function above (*plotScores*).   \n",
    "4. Describe the behaviour of the scores found during the training. Did the train or the test set produce the best results? What do these results mean? \n",
    "5. Did the MLP do better or worse than the Baseline Logistic Regression Model (and by how much)? Why do you think that it did better/worse?\n",
    "6. Here we track the *score* as we train the model. This is useful to track how the training is going. Given your previous answer on what the *score* is, what would be another useful metric to track while training these models. Specifically, what are we *minimizing* while training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO part 1 - Create the train_and_evaluate function\n",
    "# def train_and_evaluate(...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO part 2\n",
    "# Train for *10* epochs, NOT 1. This will take a while so be patient!\n",
    "# You may see a warning message, this is because we defined clf_mlp to stop early if a condition is met.\n",
    "# In reality, you would want the model to go for as long as it needs to appropriately learn from the training set.\n",
    "train_scores_mlp, test_scores_mlp = train_and_evaluate(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO part 3 - Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO part 4    \n",
    "Describe the behaviour of the scores found during the training. Did the train or the test set produce the best results? What do these results mean?  \n",
    "...   \n",
    "\n",
    "TO DO part 5   \n",
    "Did the MLP do better or worse than the Baseline Logistic Regression Model (and by how much)? Why do you think that it did better/worse?  \n",
    "...  \n",
    "\n",
    "TO DO part 6   \n",
    "Here we track the *score* as we train the model. This is useful to track how the training is going. Given your previous answer on what the *score* is, what would be another useful metric to track while training these models. Specifically, what are we *minimizing* while training?    \n",
    "...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Trying a slightly different model with different feature selection**  \n",
    "Now that we have run through the Baseline and the MLP classifiers, let us try one more MLP with a smaller feature selection. This time you will be creating the model by with random features to use from our original list of features. The following TO DO gives an overview of the entire task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 - 5 marks**   \n",
    "First, insert a seed of your choice for the randomization.  \n",
    "Create a new list of features containing a random four features from featureSet, we call this list randomFeatures. Then use that list to complete the encoding process using ohe_rand.   \n",
    "Once done, use the train_and_evaluate() function to train the model with the new training set. Plot the results. Finally compare the train and test results from clf_rand (obtained here) with the results from clf_mlp (state which did better, posting the scores and the random feature set selected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Setup a seed\n",
    "random.seed(...)\n",
    "\n",
    "# Setting up our one-hot encoder\n",
    "ohe_rand = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Since the dataset is quite large, try with a subset of features\n",
    "featureSet = ['race','gender','age', 'weight', 'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    " 'num_medications']\n",
    "\n",
    "# TO DO - Select a random four unique features from the list featureSet\n",
    "# randomFeatures = ...\n",
    "# print(randomFeatures)\n",
    "\n",
    "# TO DO - Finish the remaining encoding process\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rand = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(150, 150), random_state=5, max_iter=120, learning_rate_init=0.01, warm_start=True)\n",
    "\n",
    "# TO DO - Train the model (this will take a little while! Grab a snack or find something to do), plot the results\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO - State the random feature set obtained. Compare the train and test results from clf_rand to clf_mlp, posting the scores from both.   \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Looking at the loss curve**  \n",
    "We will do one final run of a MLP, but this time we will use solver=\"SGD\". Using this allows us to look at the loss curve during it's training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgd = MLPClassifier(solver='sgd', alpha=1e-4, hidden_layer_sizes=(150, 150), random_state=1, max_iter=150, learning_rate_init=0.1, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the loss from the trained model\n",
    "# NOTE: clf.loss_curve_ only exists when using solver=\"SGD\"\n",
    "def plot_loss(clf):\n",
    "    plt.plot(clf.loss_curve_)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q10 - 3 marks**   \n",
    "Train and evaluate the model using train_and_evaluate (for 1 epoch*) on X_train_sf_encoded and X_test_sf_encoded. Display the plot exhibiting the loss function when being trained. Briefly describe what the loss function represents (and why it's important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for *1 epoch* (with X_train_sf_encoded and X_test_sf_encoded)\n",
    "# ...\n",
    "# Plot the loss of clf_sgd\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO - What does the loss curve represent and why is it important?   \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Optional - 0 marks, just for fun**   \n",
    "Play around with the MLPClassifier by modifying the hyperparameters and selecting specific features to optimize the test score.   \n",
    "\n",
    "**Another optional task is to use the Keras Scikit-Learn wrapper**  \n",
    "\n",
    "You will need to pip install keras beforehand, but this will drastically reduce the training time for simple models such as the ones that we have worked with above. Below is just one example of how to create a model with this wrapper.  \n",
    "\n",
    "```python   \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(150, input_dim=241, activation=\"relu\"))\n",
    "    model.add(Dense(150, activation=\"relu\"))\n",
    "    model.add(Dense(3, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "   \n",
    "model = KerasClassifier(build_fn=create_model, epochs=10)\n",
    "history = model.fit(X_train_sf_encoded, y_train)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SIGNATURE:***\n",
    "My name is --------------------------.\n",
    "My student number is -----------------.\n",
    "I certify being the author of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
